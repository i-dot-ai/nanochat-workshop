# ðŸ¤– Model Architecture (11:15 - 12:15)

**Lead: Mark**

Transformer architecture deep dive.

## Topics

- Attention mechanism
- Multi-head attention
- Feed-forward networks
- Positional encodings
- Layer normalisation

## Materials

TODO: Add slides, worksheets, and exercises
